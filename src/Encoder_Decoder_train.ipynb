{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9db90a3",
   "metadata": {},
   "source": [
    "# CNN+LSTM の Encoder-Decoderモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8f08c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from SSRW_encoder_decoder import SSRWEncoderDecoder\n",
    "from Trainer import Trainer, SpeakingDataset, collate_fn, DatasetHolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef722fa7",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f21ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "lstm_hidden_dim = 128\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76ee611",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a7b86f",
   "metadata": {},
   "source": [
    "## データセット、データロードの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6723e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetHolder = DatasetHolder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ca74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_valid, dataset_test = datasetHolder.get_all_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6225ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader_train = DataLoader(dataset_train,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=collate_fn)\n",
    "dataLoader_valid = DataLoader(dataset_valid,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=collate_fn)\n",
    "dataLoader_test = DataLoader(dataset_test,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a66fc580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasetHolder.dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c0110",
   "metadata": {},
   "source": [
    "## モデルのインスタンス化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa977d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSRWEncoderDecoder(vocab_size=len(datasetHolder.dict)+4,\n",
    "                           hidden_dim_encoder=lstm_hidden_dim,\n",
    "                           hidden_dim_decoder=lstm_hidden_dim,\n",
    "                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab783f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29ccbe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  dataloader_train=dataLoader_train,\n",
    "                  dataloader_valid=dataLoader_valid,\n",
    "                  criterion=criterion,\n",
    "                  optimizer=optimizer,\n",
    "                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1ed5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './enocder_decoder.pth'\n",
    "torch.save(model.to('cpu').state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dae0b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024526596069335938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 0,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 20,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd528f268aad4e7a94cc38d153dc84b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlstm_hidden_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sources/Trainer.py:51\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs, batch_size, hidden_dim)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_train):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m     images, label \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/sources/Trainer.py:214\u001b[0m, in \u001b[0;36mSpeakingDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    213\u001b[0m     tokens\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdict[label])\n\u001b[0;32m--> 214\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(tokens)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m images, tokens\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=EPOCHS, batch_size=BATCH_SIZE, hidden_dim=lstm_hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8067202",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './enc_dec.pth'\n",
    "torch.save(music_arranger.to('cpu').state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b032009e",
   "metadata": {},
   "source": [
    "## Plot and Save Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3aeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "loss_dict = {'train_loss': trainer.train_loss_list,\n",
    "             'valid_loss': trainer.valid_loss_list,\n",
    "             'train_acc': trainer.train_acc_list,\n",
    "             'valid_acc': trainer.valid_acc_list}\n",
    "df = pd.DataFrame(loss_dict)\n",
    "df.to_csv('./enc_dec_losses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d293ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./enc_dec_losses.csv')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax1 = plt.subplots()\n",
    "x = np.array([i for i in range(EPOCH)])\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.plot(x, df['train_loss'], label='train_loss')\n",
    "ax1.plot(x, df['valid_loss'], label='valid_loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, df['train_acc'], label='train_acc')\n",
    "ax2.plot(x, df['valid_acc'], label='valid_acc')\n",
    "ax2.legend()\n",
    "\n",
    "ax1.set_ylabel('loss')\n",
    "ax2.set_ylabel('acc')\n",
    "plt.savefig('./graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdffc1f",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './enc_dec.pth'\n",
    "model = SSRWEncoderDecoder\n",
    "model.load_state_dict(torch.load(save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
